{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "DataSet = \"model_input.npy\"  # 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"获取数据\"\"\"\n",
    "    arr=np.load(filename,allow_pickle=True)\n",
    "    arr1=[]\n",
    "    arr2=[]\n",
    "    for i in range(len(arr)):\n",
    "        arr1.append(arr[i][0])\n",
    "        arr2.append(arr[i][1])\n",
    "    return arr1,arr2,len(arr1)\n",
    "    \n",
    "class CifarData:\n",
    "    \"\"\"打乱数据集\"\"\"\n",
    "    def __init__(self, filenames, need_shuffle):  # 训练集需要打乱\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        '''for filename in filenames:\n",
    "            data, labels = load_data(filename)\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)'''\n",
    "        data,labels,data_size=load_data(filenames)\n",
    "        all_data.append(data)\n",
    "        all_labels.append(labels)\n",
    "        self._size=data_size\n",
    "        self._data = np.vstack(all_data)  # 转为纵向矩阵,10000组，每组3072数\n",
    "        self._data = np.reshape(self._data,(len(self._data),-1))  # 转为纵向矩阵,10000组，每组3072数\n",
    "        # print(self._data)\n",
    "        self._labels = np.hstack(all_labels)  # 转为横向矩阵，10000个数\n",
    "        # print(self._data.shape)\n",
    "        # print(self._labels.shape)\n",
    "        \n",
    "        self._num_examples = self._data.shape[0]  # 训练集总数量\n",
    "        # print(self._num_examples)\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0  # 当前遍历数据集的位置\n",
    "        if self._need_shuffle:  # 判断是否需要打乱数据\n",
    "            self._shuffle_data()\n",
    "    def getSize(self):\n",
    "        return self._size\n",
    "\n",
    "    def _shuffle_data(self):  # 打乱数据\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "    \n",
    "    def next_batch(self, batch_size):  # 数据分组，每次取不同的组\n",
    "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:  # 考察位置大于总数，重新打乱数据，重新分组\n",
    "            if self._need_shuffle:  # 可以打乱\n",
    "                self._shuffle_data()  # 重新打乱\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:  # 分块大小过大\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "    \n",
    "# train_data=CifarData(\"train_file_1.npy\",True)\n",
    "test_data=CifarData(\"数据包/test_file_1.npy\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_wrapper(inputs,name,output_channel=32,\\\n",
    "    kernel_size=(3,3),strides=1,activation=tf.nn.relu):\n",
    "    \"\"\"卷积层装饰器\"\"\"\n",
    "    # with batch normalization:conv->bn->activation\n",
    "    with tf.name_scope(name):\n",
    "        conv2d=tf.layers.conv2d(inputs,\n",
    "                         output_channel,\n",
    "                         kernel_size,\n",
    "                         strides=strides,\n",
    "                         padding='same',\n",
    "                         activation=None,\n",
    "                         trainable=False,\n",
    "                         data_format='channels_first',\n",
    "                         name=name+'/conv2d')\n",
    "        bn=tf.layers.batch_normalization(conv2d, training=False,trainable=False)\n",
    "        return activation(bn)\n",
    "        \n",
    "def pooling_wrapper(inputs,name):\n",
    "    \"\"\"池化层装饰器\"\"\"\n",
    "    return tf.layers.max_pooling2d(inputs,(2,2),(2,2),name=name,padding='same',data_format='channels_first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义计算图\n",
    "x = tf.placeholder(tf.float32, [None, 11264])  # 设置占位符\n",
    "x_image=tf.reshape(x,[-1,1,88,128])  # 图像规模\n",
    "x_image=tf.transpose(x_image,perm=[0,2,3,1])  # 通道转换\n",
    "y = tf.placeholder(tf.int64, [None])  # y为的标注\n",
    "\n",
    "#conv1\n",
    "conv1_1=conv_wrapper(x_image,'conv1_1')\n",
    "conv1_2=conv_wrapper(conv1_1,'conv1_2')\n",
    "conv1_3=conv_wrapper(conv1_2,'conv1_3')\n",
    "pooling1=pooling_wrapper(conv1_3,'pool1')\n",
    "#conv2\n",
    "conv2_1=conv_wrapper(pooling1,'conv2_1',output_channel=64)\n",
    "conv2_2=conv_wrapper(conv2_1,'conv2_2',output_channel=64)\n",
    "conv2_3=conv_wrapper(conv2_2,'conv2_3',output_channel=64)\n",
    "pooling2=pooling_wrapper(conv2_3,'pool2')\n",
    "#conv3\n",
    "conv3_1=conv_wrapper(pooling2,'conv3_1',output_channel=64)\n",
    "conv3_2=conv_wrapper(conv3_1,'conv3_2',output_channel=64)\n",
    "conv3_3=conv_wrapper(conv3_2,'conv3_3',output_channel=64)\n",
    "pooling3=pooling_wrapper(conv3_3,'pool3')\n",
    "\n",
    "#flat(平坦化)\n",
    "flatten=tf.layers.flatten(pooling3)  # 在保留第0轴的情况下对输入的张量进行Flatten(扁平化)\n",
    "#输出 全连接层 输出形状[?,10]\n",
    "logits=tf.layers.dense(flatten,10)  # 全连接层\n",
    "\n",
    "loss=tf.losses.sparse_softmax_cross_entropy(labels=y,logits=logits)  # 交叉熵损失函数：y_->softmax,y->onhot,loss=ylogy_\n",
    "\n",
    "predict = tf.argmax(logits,1)  # 样本中分布的最大值的位置，得到index\n",
    "\n",
    "correct_prediction = tf.equal(predict, y)  # 相等为1，不相等为0\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))  # 平均数即为准确率\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)  # adam优化器，定义梯度下降方法，使损失函数最小\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./VGGModel/VGG19999.ckpt\n",
      "ID:0 correct_label:1 predict_label:1\n",
      "ID:1 correct_label:1 predict_label:1\n",
      "ID:2 correct_label:1 predict_label:1\n",
      "ID:3 correct_label:1 predict_label:1\n",
      "ID:4 correct_label:1 predict_label:1\n",
      "ID:5 correct_label:2 predict_label:1\n",
      "ID:6 correct_label:1 predict_label:1\n",
      "ID:7 correct_label:1 predict_label:1\n",
      "ID:8 correct_label:1 predict_label:1\n",
      "ID:9 correct_label:1 predict_label:1\n",
      "ID:10 correct_label:2 predict_label:1\n",
      "ID:11 correct_label:1 predict_label:1\n",
      "ID:12 correct_label:2 predict_label:1\n",
      "ID:13 correct_label:1 predict_label:1\n",
      "ID:14 correct_label:1 predict_label:1\n",
      "ID:15 correct_label:1 predict_label:1\n",
      "ID:16 correct_label:1 predict_label:1\n",
      "ID:17 correct_label:1 predict_label:1\n",
      "ID:18 correct_label:1 predict_label:1\n",
      "ID:19 correct_label:1 predict_label:1\n",
      "ID:20 correct_label:1 predict_label:1\n",
      "ID:21 correct_label:1 predict_label:1\n",
      "ID:22 correct_label:1 predict_label:1\n",
      "ID:23 correct_label:1 predict_label:1\n",
      "ID:24 correct_label:1 predict_label:1\n",
      "ID:25 correct_label:1 predict_label:1\n",
      "ID:26 correct_label:2 predict_label:1\n",
      "ID:27 correct_label:1 predict_label:1\n",
      "ID:28 correct_label:1 predict_label:1\n",
      "ID:29 correct_label:1 predict_label:1\n",
      "ID:30 correct_label:1 predict_label:1\n",
      "ID:31 correct_label:1 predict_label:1\n",
      "ID:32 correct_label:1 predict_label:1\n",
      "ID:33 correct_label:1 predict_label:1\n",
      "ID:34 correct_label:1 predict_label:1\n",
      "ID:35 correct_label:1 predict_label:1\n",
      "ID:36 correct_label:1 predict_label:1\n",
      "ID:37 correct_label:1 predict_label:1\n",
      "ID:38 correct_label:1 predict_label:1\n",
      "ID:39 correct_label:1 predict_label:1\n",
      "ID:40 correct_label:1 predict_label:1\n",
      "ID:41 correct_label:2 predict_label:1\n",
      "ID:42 correct_label:2 predict_label:1\n",
      "ID:43 correct_label:1 predict_label:1\n",
      "ID:44 correct_label:2 predict_label:1\n",
      "ID:45 correct_label:1 predict_label:1\n",
      "ID:46 correct_label:1 predict_label:1\n",
      "ID:47 correct_label:1 predict_label:1\n",
      "ID:48 correct_label:1 predict_label:1\n",
      "ID:49 correct_label:1 predict_label:1\n",
      "ID:50 correct_label:1 predict_label:1\n",
      "ID:51 correct_label:1 predict_label:1\n",
      "ID:52 correct_label:1 predict_label:1\n",
      "ID:53 correct_label:1 predict_label:1\n",
      "ID:54 correct_label:1 predict_label:1\n",
      "ID:55 correct_label:1 predict_label:1\n",
      "ID:56 correct_label:1 predict_label:1\n",
      "ID:57 correct_label:1 predict_label:1\n",
      "ID:58 correct_label:1 predict_label:1\n",
      "ID:59 correct_label:2 predict_label:1\n",
      "ID:60 correct_label:1 predict_label:1\n",
      "ID:61 correct_label:1 predict_label:1\n",
      "ID:62 correct_label:1 predict_label:1\n",
      "ID:63 correct_label:1 predict_label:1\n",
      "ID:64 correct_label:1 predict_label:1\n",
      "ID:65 correct_label:1 predict_label:1\n",
      "ID:66 correct_label:1 predict_label:1\n",
      "ID:67 correct_label:1 predict_label:1\n",
      "ID:68 correct_label:1 predict_label:1\n",
      "ID:69 correct_label:1 predict_label:1\n",
      "ID:70 correct_label:1 predict_label:1\n",
      "ID:71 correct_label:1 predict_label:1\n",
      "ID:72 correct_label:1 predict_label:1\n",
      "ID:73 correct_label:2 predict_label:1\n",
      "ID:74 correct_label:2 predict_label:1\n",
      "ID:75 correct_label:1 predict_label:1\n",
      "ID:76 correct_label:2 predict_label:1\n",
      "ID:77 correct_label:1 predict_label:1\n",
      "ID:78 correct_label:1 predict_label:1\n",
      "ID:79 correct_label:1 predict_label:1\n",
      "ID:80 correct_label:1 predict_label:1\n",
      "ID:81 correct_label:1 predict_label:1\n",
      "ID:82 correct_label:1 predict_label:1\n",
      "ID:83 correct_label:1 predict_label:1\n",
      "ID:84 correct_label:1 predict_label:1\n",
      "ID:85 correct_label:1 predict_label:1\n",
      "ID:86 correct_label:1 predict_label:1\n",
      "ID:87 correct_label:1 predict_label:1\n",
      "ID:88 correct_label:1 predict_label:1\n",
      "ID:89 correct_label:1 predict_label:1\n",
      "ID:90 correct_label:1 predict_label:1\n",
      "ID:91 correct_label:2 predict_label:1\n",
      "ID:92 correct_label:1 predict_label:1\n",
      "ID:93 correct_label:1 predict_label:1\n",
      "ID:94 correct_label:1 predict_label:1\n",
      "ID:95 correct_label:1 predict_label:1\n",
      "ID:96 correct_label:1 predict_label:1\n",
      "ID:97 correct_label:1 predict_label:1\n",
      "ID:98 correct_label:1 predict_label:1\n",
      "ID:99 correct_label:1 predict_label:1\n",
      "ID:100 correct_label:1 predict_label:1\n",
      "ID:101 correct_label:1 predict_label:1\n",
      "ID:102 correct_label:1 predict_label:1\n",
      "ID:103 correct_label:1 predict_label:1\n",
      "ID:104 correct_label:1 predict_label:1\n",
      "ID:105 correct_label:2 predict_label:1\n",
      "ID:106 correct_label:2 predict_label:1\n",
      "ID:107 correct_label:1 predict_label:1\n",
      "ID:108 correct_label:2 predict_label:1\n",
      "ID:109 correct_label:1 predict_label:1\n",
      "ID:110 correct_label:2 predict_label:1\n",
      "ID:111 correct_label:1 predict_label:1\n",
      "ID:112 correct_label:2 predict_label:1\n",
      "ID:113 correct_label:1 predict_label:1\n",
      "ID:114 correct_label:1 predict_label:1\n",
      "ID:115 correct_label:1 predict_label:1\n",
      "ID:116 correct_label:1 predict_label:1\n",
      "ID:117 correct_label:1 predict_label:1\n",
      "ID:118 correct_label:1 predict_label:1\n",
      "ID:119 correct_label:1 predict_label:1\n",
      "ID:120 correct_label:1 predict_label:1\n",
      "ID:121 correct_label:1 predict_label:1\n",
      "ID:122 correct_label:1 predict_label:1\n",
      "ID:123 correct_label:1 predict_label:1\n",
      "ID:124 correct_label:1 predict_label:1\n",
      "ID:125 correct_label:1 predict_label:1\n",
      "ID:126 correct_label:2 predict_label:1\n",
      "ID:127 correct_label:1 predict_label:1\n",
      "ID:128 correct_label:1 predict_label:1\n",
      "ID:129 correct_label:1 predict_label:1\n",
      "ID:130 correct_label:1 predict_label:1\n",
      "ID:131 correct_label:1 predict_label:1\n",
      "ID:132 correct_label:1 predict_label:1\n",
      "ID:133 correct_label:2 predict_label:1\n",
      "ID:134 correct_label:1 predict_label:1\n",
      "ID:135 correct_label:1 predict_label:1\n",
      "ID:136 correct_label:1 predict_label:1\n",
      "ID:137 correct_label:1 predict_label:1\n",
      "ID:138 correct_label:1 predict_label:1\n",
      "ID:139 correct_label:1 predict_label:1\n",
      "ID:140 correct_label:1 predict_label:1\n",
      "ID:141 correct_label:1 predict_label:1\n",
      "ID:142 correct_label:2 predict_label:1\n",
      "ID:143 correct_label:2 predict_label:1\n",
      "ID:144 correct_label:2 predict_label:1\n",
      "ID:145 correct_label:1 predict_label:1\n",
      "ID:146 correct_label:2 predict_label:1\n",
      "ID:147 correct_label:2 predict_label:1\n",
      "ID:148 correct_label:1 predict_label:1\n",
      "ID:149 correct_label:1 predict_label:1\n",
      "ID:150 correct_label:2 predict_label:1\n",
      "ID:151 correct_label:1 predict_label:1\n",
      "ID:152 correct_label:1 predict_label:1\n",
      "ID:153 correct_label:2 predict_label:1\n",
      "ID:154 correct_label:1 predict_label:1\n",
      "ID:155 correct_label:2 predict_label:1\n",
      "ID:156 correct_label:2 predict_label:1\n",
      "ID:157 correct_label:2 predict_label:1\n",
      "ID:158 correct_label:1 predict_label:1\n",
      "ID:159 correct_label:2 predict_label:1\n",
      "ID:160 correct_label:1 predict_label:1\n",
      "ID:161 correct_label:2 predict_label:1\n",
      "ID:162 correct_label:1 predict_label:1\n",
      "ID:163 correct_label:2 predict_label:1\n",
      "ID:164 correct_label:1 predict_label:1\n",
      "ID:165 correct_label:1 predict_label:1\n",
      "ID:166 correct_label:1 predict_label:1\n",
      "ID:167 correct_label:1 predict_label:1\n",
      "ID:168 correct_label:1 predict_label:1\n",
      "ID:169 correct_label:2 predict_label:1\n",
      "ID:170 correct_label:1 predict_label:1\n",
      "ID:171 correct_label:1 predict_label:1\n",
      "ID:172 correct_label:1 predict_label:1\n",
      "ID:173 correct_label:1 predict_label:1\n",
      "ID:174 correct_label:2 predict_label:1\n",
      "ID:175 correct_label:2 predict_label:1\n",
      "ID:176 correct_label:2 predict_label:1\n",
      "ID:177 correct_label:1 predict_label:1\n",
      "ID:178 correct_label:2 predict_label:1\n",
      "ID:179 correct_label:2 predict_label:1\n",
      "ID:180 correct_label:1 predict_label:1\n",
      "ID:181 correct_label:1 predict_label:1\n",
      "ID:182 correct_label:2 predict_label:1\n",
      "ID:183 correct_label:1 predict_label:1\n",
      "ID:184 correct_label:1 predict_label:1\n",
      "ID:185 correct_label:2 predict_label:1\n",
      "ID:186 correct_label:1 predict_label:1\n",
      "ID:187 correct_label:2 predict_label:1\n",
      "ID:188 correct_label:2 predict_label:1\n",
      "ID:189 correct_label:2 predict_label:1\n",
      "ID:190 correct_label:2 predict_label:1\n",
      "ID:191 correct_label:1 predict_label:1\n",
      "ID:192 correct_label:2 predict_label:1\n",
      "ID:193 correct_label:1 predict_label:1\n",
      "ID:194 correct_label:2 predict_label:1\n",
      "ID:195 correct_label:1 predict_label:1\n",
      "ID:196 correct_label:1 predict_label:1\n",
      "ID:197 correct_label:1 predict_label:1\n",
      "ID:198 correct_label:1 predict_label:1\n",
      "ID:199 correct_label:1 predict_label:1\n",
      "ID:200 correct_label:2 predict_label:1\n",
      "ID:201 correct_label:1 predict_label:1\n",
      "ID:202 correct_label:1 predict_label:1\n",
      "ID:203 correct_label:1 predict_label:1\n",
      "ID:204 correct_label:1 predict_label:1\n",
      "ID:205 correct_label:2 predict_label:1\n",
      "ID:206 correct_label:2 predict_label:1\n",
      "ID:207 correct_label:2 predict_label:1\n",
      "ID:208 correct_label:1 predict_label:1\n",
      "ID:209 correct_label:2 predict_label:1\n",
      "ID:210 correct_label:2 predict_label:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:211 correct_label:1 predict_label:1\n",
      "ID:212 correct_label:1 predict_label:1\n",
      "ID:213 correct_label:2 predict_label:1\n",
      "ID:214 correct_label:1 predict_label:1\n",
      "ID:215 correct_label:1 predict_label:1\n",
      "ID:216 correct_label:2 predict_label:1\n",
      "ID:217 correct_label:1 predict_label:1\n",
      "ID:218 correct_label:2 predict_label:1\n",
      "ID:219 correct_label:2 predict_label:1\n",
      "ID:220 correct_label:2 predict_label:1\n",
      "ID:221 correct_label:1 predict_label:1\n",
      "ID:222 correct_label:2 predict_label:1\n",
      "ID:223 correct_label:2 predict_label:1\n",
      "ID:224 correct_label:2 predict_label:1\n",
      "ID:225 correct_label:1 predict_label:1\n",
      "ID:226 correct_label:1 predict_label:1\n",
      "ID:227 correct_label:1 predict_label:1\n",
      "ID:228 correct_label:1 predict_label:1\n",
      "ID:229 correct_label:2 predict_label:1\n",
      "ID:230 correct_label:1 predict_label:1\n",
      "ID:231 correct_label:2 predict_label:1\n",
      "ID:232 correct_label:1 predict_label:1\n",
      "ID:233 correct_label:0 predict_label:1\n",
      "ID:234 correct_label:0 predict_label:1\n",
      "ID:235 correct_label:1 predict_label:1\n",
      "ID:236 correct_label:1 predict_label:1\n",
      "ID:237 correct_label:2 predict_label:1\n",
      "ID:238 correct_label:2 predict_label:1\n",
      "ID:239 correct_label:2 predict_label:1\n",
      "ID:240 correct_label:2 predict_label:1\n",
      "ID:241 correct_label:1 predict_label:1\n",
      "ID:242 correct_label:1 predict_label:1\n",
      "ID:243 correct_label:2 predict_label:1\n",
      "ID:244 correct_label:1 predict_label:1\n",
      "ID:245 correct_label:2 predict_label:1\n",
      "ID:246 correct_label:1 predict_label:1\n",
      "ID:247 correct_label:2 predict_label:1\n",
      "ID:248 correct_label:1 predict_label:1\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "# 执行计算图\n",
    "correct_result=[[] for x in range(40)]\n",
    "predict_result=[[] for x in range(40)]\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()  # 变量初始化\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, \"./VGGModel/VGG19999.ckpt\")\n",
    "    corr_cnt=0\n",
    "    for i in range(test_data.getSize()):\n",
    "        datas,labels=test_data.next_batch(1)\n",
    "        pre_val = sess.run(\n",
    "            predict,\n",
    "            feed_dict={\n",
    "                x: datas,\n",
    "                y: labels})\n",
    "        print('ID:%d correct_label:%d predict_label:%d' % (i,labels[0],pre_val))\n",
    "        correct_result[labels[0]].append([i,pre_val[0]])\n",
    "        predict_result[pre_val[0]].append([i,labels[0]])\n",
    "        if labels[0]==pre_val:\n",
    "            corr_cnt=corr_cnt+1\n",
    "    print(corr_cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据报文数目：249\n",
      "整体准确率：0.7149\n",
      "SSL      \tTP:0 \tFN:2 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "TCP      \tTP:178 \tFN:0 \tFP:71 \t召回率:1.0000 \t精准度:0.7149 \tf1值:0.8337\n",
      "TLSv1.2  \tTP:0 \tFN:69 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "ARP      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "NBNS     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "LLMNR    \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "DNS      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "NTP      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "TLSv1    \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "UDP      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "SNMP     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "HTTP     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "SSDP     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "MDNS     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "DHCPv6   \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "DB-LSP-DISC \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "STP      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "LLC      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "BROWSER  \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "LLDP     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "IPX      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "IGMPv2   \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "ICMPv6   \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "DHCP     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "VNC      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "SRVLOC   \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "OCSP     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "ICMP     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "STUN     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "DTLSv1.0 \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "IGMPv3   \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "GQUIC    \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "NBSS     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "SMB      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "SMB2     \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "LANMAN   \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "DCERPC   \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "SPOOLSS  \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "FTP      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n",
      "X11      \tTP:0 \tFN:0 \tFP:0 \t召回率:0 \t精准度:0 \tf1值:0\n"
     ]
    }
   ],
   "source": [
    "dic=np.load(\"数据包/protocol_dictionary.npy\",allow_pickle=True)[()]  # 协议字典\n",
    "print(\"数据报文数目：%d\" % test_data.getSize())\n",
    "print(\"整体准确率：%.4f\" % (corr_cnt/test_data.getSize()))\n",
    "# 协议准确率、召回率等...\n",
    "for i in range(40):\n",
    "    TP=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    for j in range(len(correct_result[i])):\n",
    "        if(correct_result[i][j][1]==i):  # 预测正确\n",
    "            TP+=1\n",
    "        if(correct_result[i][j][1]!=i):  # 真预测为假\n",
    "            FN+=1\n",
    "    for j in range(len(predict_result[i])):\n",
    "        if(predict_result[i][j][1]!=i):  # 假预测为真\n",
    "            FP+=1\n",
    "    if TP==0:\n",
    "        print(\"%-8s \\tTP:0 \\tFN:%d \\tFP:%d \\t召回率:0 \\t精准度:0 \\tf1值:0\" % (list(dic.keys())[i],FN,FP))\n",
    "        continue    \n",
    "    recall=TP/(TP+FN)\n",
    "    prec=TP/(TP+FP)\n",
    "    f1=2*recall*prec/(recall+prec)\n",
    "    print(\"%-8s \\tTP:%d \\tFN:%d \\tFP:%d \\t召回率:%.4f \\t精准度:%.4f \\tf1值:%.4f\" % (list(dic.keys())[i],TP,FN,FP,recall,prec,f1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
